
---
title: "Very useful tools in R for Geospatial Analysis"
output: github_document
---
  
  In this document, I will explain some very useful and easy 
  tools that I use in R for geospatial analysis and for spatial object
  manipulation (e.g shapefiles, raster files,
  spatial databases, etc.). I also going to present some libraries and 
  commands that I usually use in my-day-to-day code work for cleaning 
  and dataset manipulation (Stata alike)
  
  For all this I'm going to use mainly examples of public databases
  from the Peruvian context (the country that I come from). This is going to be 
  a very short post, but I'm going to try to include great variety of tools
  at least for every basic analysis (e.g open spatial object, modify them, plot
  maps, polygons, points, etc.)
  

  ```{r, warning=FALSE,message=FALSE}
  
    rm(list = ls()) # to clear your working spaces

    # These are the libraries that we are going to use for this small post
    
  library(sp)
  library(rgdal)
  library(raster)
  library(maptools)
  library(rgeos)
    
    # For special graphs:
    
    library(ggplot2)
    library(tidyverse)
    library(broom)
    
    library(classInt) # for breaks graphs 
    library(RColorBrewer) # Color palette for maps 
    
    # For string
    library(stringr)
    
    # For databases 
    library(readstata13)
    library(dplyr)
    library(gdata)
    
  ```
  
## Level 0: Setup, open and inspect spatial object
  
  Open shapefiles:
  
  ```{r}
    mun <- readOGR(paste0("~/Dropbox/paulo_RA/Narcos/databases/municipios/update"), 
                          "BAS_LIM_DISTRITOS") # rgdal library
                          
    # An easly inspect some objects:
    plot(mun)
    
  ```
  
  Of course, we are able not only to open a shp but even a latlong file and 
  transform it to a GIS kind of object. See for example:
  
  ```{r}
    enaho <- read.dta13(paste0("~/Dropbox/BDatos/ENAHO/2020/737-Modulo01/",
      "enaho01-2020-100.dta")) # Kind of large dataset around 50k observations
    
    # However we can easly handle this as an spatial object:
    
    coordinates(enaho) <- ~ longitud + latitud
  
    # A very important thing is to identify coords systm. For usual lat/long 
    # the following works:
    
    proj4string(enaho) <- CRS("+init=epsg:4326") # Here we are defining the coord syst.
      # sp library
    
    plot(enaho) # And we can plot it 
  ```
  
  Now we have in our R work enviroment two spatial objects, a polygon object, 
  Peruvian municipalities, and a point object, Peruvian household for the Annual
  National Survey (ENAHO). Of course we can print this together in a graph, but 
  first we need to check if both spatial objects have the same coords system
  
  ```{r}
    print(crs(enaho))
    print(crs(mun)) ## crs from raster library
  ```
  
  As you may see, the municipality dataset is in UTM coord system (projected in 
  meters), and the household survey is in standard latlong coordinates. We can
  easily transform everything in UTM coords (it is going to be useful later on)
  as follow:
  
  ``` {r}
    enaho <- spTransform(enaho, crs(mun))
    
    # And of course we can plot it together in a graph, and add one more 
    # shapeline of lines 
    
    # Rivers in Peru:
    
    rivers <- readOGR(paste0("~/Dropbox/BDatos/Shape/PER_wat"), 
                          "PER_water_areas_dcw") 
                          
    rivers <- spTransform(rivers, crs(mun)) # just in case is in other crs 
    
    
    plot(mun, lwd = .1) # And we can plot it 
    plot(rivers, add = TRUE, border = "blue") # add lines
    plot(enaho, add = TRUE, col='red', pch=1, cex = .1) # add points 
    
  ```
  
  Of course these are not the most rad graphs, but they accomplish their
  main purpose inspect the element. I will do another post with more
  stylish figures ;)
    
## Level 1: Basic operations
  
  We've already discussed the initial steps for any geographic analysis. Now I
  am going to present some of the most basic operations that we can perform on
  spatial objects. The good thing is that actually, we can do everything 
  that we used to do on a regular datasets (subsetting, math operations, 
  bysorts, conditionals, etc...)

  ``` {r}
  
    # Subsample
    mun <- mun[mun$NOMBPROV == 'LIMA',] # easily subsampling
    
    # Manipulating variables

    # We are going to create a dummy for the newest districts in Lima
    
    # But first, we need to do a little of cleaning, we can easily do this in R
    # even if it is an spatial object
    
    # Inspect the data
    
    sample_n(mun@data[,c("IDDIST", "NOMBDIST", "FECHA", "AREA_MINAM")], 15)
    
    # Substring last digits and convert tu numeric variable 
    
    mun$year_creation <- as.numeric(str_sub(mun$FECHA, -4))
    
    print(sum(is.na(mun$year_creation))) ## NA because raw variable
    
    mun$year_creation[is.na(mun$year_creation)] <- 1821 # replace with correct value 
    
    print(sum(is.na(mun$year_creation))) ## Fixed
    
    # Check it again:
    
    sample_n(mun@data[,c("IDDIST", "NOMBDIST", "year_creation", "AREA_MINAM")], 10)
    
    # We can also easily summarize the year variable and any other:
    
    print(summary(mun$year_creation))
    
    # Now we can create a dummy variable for the newest district, and plot them in a
    # map 
    
    mun$new_district <- ifelse(mun$year_creation>1980, 1, 0)
    
    # In more fancy way :) 
    
    plot(mun, col = "lightgrey",
         main = "Lima Municipalities")
    
    sel <- mun$new_district == 1 # regions with new districts for graph 
    
    plot(mun[ sel, ], col = "red", add = TRUE) # add selected zones to map
    legend("bottomright", title = "Year of creation",
           legend = c("After 1980s", "Before"),
           fill = c("red", "lightgrey"),
           cex = .7)

    # We can rename variables and keep only a few vars:
    
    mun <- mun[, c("IDDIST", "NOMBDIST", "year_creation", 
                   "new_district", "AREA_MINAM")]
    
    # And rename the variable that we want: 
    
    mun <- rename.vars(mun, c("IDDIST", "NOMBDIST", "AREA_MINAM"), 
           c("ubigeo", "distrito", "area_mun")) 
           
    # And verified cleaned data:
    
    print(mun@data)
    print(typeof(mun)) # and we are still dealing with a spatial object 

    # Other variables (but for our point spatial object)
    
    enaho$prov_id = substr(enaho$ubigeo,1,4) # creating an prov ID
    enaho$household_id = paste0(enaho$ubigeo, enaho$conglome, enaho$vivienda, 
                          enaho$hogar) # creating a household ID
    
    # We of course can quickly check what we did (in 10 random rows):
    
    sample_n(enaho@data[,c("ubigeo", "conglome", "vivienda", 
                           "hogar", "prov_id", "household_id")], 10) 
                           
    # Notice the use of @data in the previous command, sometimes, we need to 
    # be more specific with R (but in most of the cases
    # we can treat spatial dataframe just as a regular dataframe
    
    # Our household ID is unique of course 
    print(length(enaho$household_id)) # Number of rows 
    print(length(unique(enaho$household_id))) # Number of unique rows 
    
    # We can check the number of municipalities and provinces too 
    
    print(length(unique(enaho$ubigeo)))
    print(length(unique(enaho$prov_id)))
    
    # We are going to subsample our household database too, in order to match with 
    # the mun database 
    
    enaho <- enaho[enaho$prov_id == '1501',] # LIMA province
    
    # And we can check our subsampling:
    
    plot(mun, lwd = .5) # And we can plot it 
    plot(enaho, add = TRUE, col='red', pch=1, cex = .1) # add points
    
  ```
  
  And of course, as we can transform regular dataframes with lat/long to 
  spatial objects, we are able to turn them back to regular dataframes (this
  can be useful in several cases, e.g when you would like to reduce estimation
  time). Moreover, we can perform other more 'complicated' data operations, like 
  merge with other data information.
  
  ``` {r}
  
    enaho.df <- as.data.frame(enaho)
    
    # We are going to aggregate this data to merge it with our spatial database 
    
    enaho.ubigeo <- (enaho.df %>% group_by(ubigeo) %>% 
                   summarize(pob_mun = sum(factor07)))
      
    # And do the merge:
    
    mun.enaho <- merge(mun, enaho.ubigeo)
    
    # And create relevant indicator such as population per 
    
    mun.enaho$density <- mun.enaho$pob_mun/mun.enaho$area_mun
    
    # And plot it (from sp library):
    
    # Figure with quantile breaks:
    
    # Here I make quantiles:
    
    pal <- brewer.pal(7, "OrRd") # we select 7 colors from the palette
    
    brks <- classIntervals(mun.enaho$density, 
                           n=7, style="jenks")$brks # breaks 
    
    # Categorical variable 
    mun.enaho$density_cat <- cut(mun.enaho$density, brks, 
                                  include.lowest = TRUE, dig.lab=3)
    # plot
    spplot(mun.enaho, "density_cat", 
           col.regions=pal, main = "Population density")

  ```
  
## Level 2: Spatial operations - spatial merge, aggregations, grid generation, and more

  In this part we are going other spatial operations 

  ``` {r}
  
    # For this new excercise, we are going to open a new database - School in 2013:

    schools <- read.dta13(paste0("~/Dropbox/BDatos/escuelas_2013.dta"))
    
    coordinates(schools) <- ~ Longitud + Latitud # transform it to spatial object
      # Note that there should no be any missing here 
    
    # defining coords:
    proj4string(schools) <- CRS("+init=epsg:4326") # standard coords
    
    plot(schools, col = "black", lwd = .5, main = "Schools in Peru - 2013")
    
    print(length(schools)) # number of schools 
    print(sample_n(schools@data, 10)) # we don't have ubigeo variable here. 
    
    # So in order to select only Lima schools, we have to do an spatial merge
    # a merge base on the caracteristics 
    
    schools <- spTransform(schools, crs(mun.enaho)) # we need first to transform the coords
    schools.lima <- over(schools, mun.enaho)
    schools.lima <- spCbind(schools, schools.lima) # Here I recover the information 
    
    schools.lima <- schools.lima@data[complete.cases(schools.lima@data), ]
    
    plot(schools.lima)
    

  ```

  